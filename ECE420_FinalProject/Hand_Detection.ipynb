{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8e6dc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error opening webcam\n",
      "Error capturing frame\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "199b97ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\norla\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import exposure\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "def trainPerceptron(train_set, train_labels, learning_rate, max_iter):\n",
    "    input_size = train_set.shape[1]\n",
    "    \n",
    "    # Initialize weights and bias\n",
    "    W = np.random.randn(input_size)\n",
    "    b = 0\n",
    "    \n",
    "    for iteration in range(max_iter):\n",
    "        for i, image in enumerate(train_set):\n",
    "            # Forward propagation\n",
    "            output = sigmoid(np.dot(image, W) + b)\n",
    "            \n",
    "            # Backpropagation\n",
    "            output_error = train_labels[i] - output\n",
    "            \n",
    "            # Update weights and bias using gradient descent\n",
    "            W += learning_rate * image * output_error\n",
    "            b += learning_rate * output_error\n",
    "    \n",
    "    return W, b\n",
    "\n",
    "def classifyPerceptron(W, b, dev_set):\n",
    "    ret = []\n",
    "    for image in dev_set:\n",
    "        output = sigmoid(np.dot(image, W) + b)\n",
    "        if output <= 0.5:\n",
    "            ret.append(0)\n",
    "        else:\n",
    "            ret.append(1)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a153cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_classes = 4 \n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def grad_log(theta, X, y):\n",
    "    m = X.shape[0]\n",
    "    h = sigmoid(X @ theta)\n",
    "    grad = (1 / m) * (X.T @ (h - y))\n",
    "    return grad\n",
    "\n",
    "def cost_log(theta, X, y):\n",
    "    m = X.shape[0]\n",
    "    h = sigmoid(X @ theta)\n",
    "    cost = (-1 / (2*m)) * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
    "    return cost\n",
    "\n",
    "def trainPerceptron(train_set, train_labels, learning_rate, max_iter):\n",
    "    input_size = train_set.shape[1]\n",
    "    theta = np.zeros((num_classes, input_size))\n",
    "\n",
    "    for c in range(num_classes):\n",
    "        y = (train_labels == c).astype(int)\n",
    "        for _ in range(max_iter):\n",
    "            grad = grad_log(theta[c], train_set, y)\n",
    "            theta[c] -= learning_rate * grad\n",
    "\n",
    "    return theta\n",
    "\n",
    "def classifyPerceptron(W, X):\n",
    "    probabilities = sigmoid(X @ W.T)\n",
    "    return np.argmax(probabilities, axis=1)\n",
    "\n",
    "\n",
    "train_set = hand_array  \n",
    "train_labels = np.concatenate((2*np.ones(1000), np.ones(1880), np.zeros(470), 3*np.ones(572))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8285d60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [2 2 2 ... 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "alpha = 10**(-6)\n",
    "num_iter = 10000\n",
    "\n",
    "# Add a column of ones to train_data\n",
    "ones = np.ones((train_set.shape[0], 1))\n",
    "train_X = np.hstack((ones, train_set))\n",
    "\n",
    "# Train the perceptron\n",
    "theta = trainPerceptron(train_X, train_labels, alpha, num_iter)\n",
    "\n",
    "# Classify using the trained perceptron\n",
    "predictions = classifyPerceptron(theta, train_X)\n",
    "\n",
    "# Print predictions or use them as needed\n",
    "print(\"Predictions:\", predictions)\n",
    "\n",
    "accuracy = [0, 0, 0, 0]\n",
    "\n",
    "counter = 0\n",
    "for i in predictions:\n",
    "    if i == train_labels[counter]:\n",
    "        accuracy[i] += 1\n",
    "    counter += 1\n",
    "accuracy[0] /= 470\n",
    "accuracy[1] /= 1880\n",
    "accuracy[2] /= 1000\n",
    "accuracy[3] /= 572"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d948d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02127659574468085, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca69e6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "hand_set = []\n",
    "count = 0\n",
    "\n",
    "files = os.listdir(r'C:\\Users\\norla\\OneDrive\\Desktop\\ThumbsUpSet')\n",
    "files2 = os.listdir(r'C:\\Users\\norla\\OneDrive\\Desktop\\ThumbsDownSet')\n",
    "files3 = os.listdir(r'C:\\Users\\norla\\OneDrive\\Desktop\\archive\\Hands\\Hands')\n",
    "files4 = os.listdir(r'C:\\Users\\norla\\OneDrive\\Desktop\\FistSet')\n",
    "\n",
    "for file_name in files3:\n",
    "    if file_name.endswith('.jpg'):\n",
    "        file_path = os.path.join(r'C:\\Users\\norla\\OneDrive\\Desktop\\archive\\Hands\\Hands', file_name)\n",
    "        image = Image.open(file_path)\n",
    "        \n",
    "        np_image = np.array(image)\n",
    "        \n",
    "        # Convert the image to grayscale\n",
    "        gray = cv2.cvtColor(np_image, cv2.COLOR_RGB2GRAY)  \n",
    "\n",
    "        # Threshold the image to separate the hand from the background\n",
    "        _, binary = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Find contours in the binary image\n",
    "        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Assuming the largest contour corresponds to the hand\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # Get the bounding rectangle of the largest contour\n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "\n",
    "        # Crop the hand region from the original image\n",
    "        hand_crop = gray[y:y+h, x:x+w]\n",
    "\n",
    "        # Resize the cropped hand region to 64x64\n",
    "        hand_resized = cv2.resize(hand_crop, (64, 64))\n",
    "        \n",
    "        # Add image to set\n",
    "        hand_set.append(hand_resized.flatten())\n",
    "        \n",
    "        count += 1\n",
    "        if count >= 1000:\n",
    "            break\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# Load images from ThumbsUpSet directory\n",
    "for i in range(20):\n",
    "    for file_name in files:\n",
    "        if file_name.endswith('.jpg'):\n",
    "            file_path = os.path.join(r'C:\\Users\\norla\\OneDrive\\Desktop\\ThumbsUpSet', file_name)\n",
    "            image = Image.open(file_path)\n",
    "            gray = image.convert('L')  # Convert to grayscale\n",
    "            hand_resized = gray.resize((64, 64))\n",
    "            hand_set.append(np.array(hand_resized).flatten())\n",
    "\n",
    "# Load images from ThumbsDownSet directory\n",
    "for i in range(5):\n",
    "    for file_name in files2:\n",
    "        if file_name.endswith('.jpg'):\n",
    "            file_path = os.path.join(r'C:\\Users\\norla\\OneDrive\\Desktop\\ThumbsDownSet', file_name)\n",
    "            image = Image.open(file_path)\n",
    "            gray = image.convert('L')  # Convert to grayscale\n",
    "            hand_resized = gray.resize((64, 64))\n",
    "            hand_set.append(np.array(hand_resized).flatten())\n",
    "            \n",
    "# Load images from FistSet directory\n",
    "for i in range(4):\n",
    "    for file_name in files4:\n",
    "        if file_name.endswith('.jpg'):\n",
    "            file_path = os.path.join(r'C:\\Users\\norla\\OneDrive\\Desktop\\FistSet', file_name)\n",
    "            image = Image.open(file_path)\n",
    "            gray = image.convert('L')  # Convert to grayscale\n",
    "            hand_resized = gray.resize((64, 64))\n",
    "            hand_set.append(np.array(hand_resized).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5613b3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3922, 4096)\n"
     ]
    }
   ],
   "source": [
    "hand_array = np.stack(hand_set)\n",
    "print(hand_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7eaa0645",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
